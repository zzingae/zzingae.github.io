---
title: "RNN"
tags:
  - Deep-learning
use_math: true
published : false
---

# RNN

<p align="center"> 
<img src="../images/RNNs.png" alt="drawing" width="800"/> 
<center>http://karpathy.github.io/2015/05/21/rnn-effectiveness/</center>
</p>

For example, the model opens a \begin{proof} environment but then ends it with a \end{lemma}. This is an example of a problem we’d have to fix manually, and is likely due to the fact that the dependency is too long-term.

<p align="center"> 
<img src="../images/RNN-seq2seq.png" alt="drawing" width="800"/> 
<center>https://github.com/tensorflow/nmt</center>
</p>

# LSTM

forget, input, output (input: [h,x], sigmoid output: 0~1 값) gate 세개를 생성하고, cell state에 대해 정보를 제거 (forget), 추가 (input), 출력 (output) 한다. 

# Backpropagation through time


# Conditional mask

<p align="center"> 
<img src="../images/maskpredict_process.gif" alt="drawing" width="800"/> 
<center>https://simonjisu.github.io/paper/2020/07/19/maskpredict.html</center>
</p>